2025-04-19 21:46:59,128 - BERT_FakeNews - INFO - Configuration des hyperparamètres:
2025-04-19 21:46:59,128 - BERT_FakeNews - INFO - {
  "MAX_LEN": 512,
  "BATCH_SIZE": 16,
  "EPOCHS": 3,
  "LEARNING_RATE": 3e-05,
  "RANDOM_SEED": 13101990,
  "MODEL_NAME": "bert-base-uncased",
  "OUTPUT_DIR": "./Modele/bert_fine_tuned/",
  "USE_MIXED_PRECISION": true
}
2025-04-19 21:46:59,150 - BERT_FakeNews - INFO - Utilisation de l'appareil: cuda
2025-04-19 21:46:59,151 - BERT_FakeNews - INFO - Chargement des données depuis data/Fake.csv et data/True.csv
2025-04-19 21:46:59,974 - BERT_FakeNews - INFO - Données fake news chargées: 23481 exemples
2025-04-19 21:47:00,719 - BERT_FakeNews - INFO - Données true news chargées: 21417 exemples
2025-04-19 21:47:00,729 - BERT_FakeNews - INFO - Total d'exemples: 44898
2025-04-19 21:47:00,731 - BERT_FakeNews - INFO - Distribution des labels: {1: 23481, 0: 21417}
2025-04-19 21:47:00,758 - BERT_FakeNews - INFO - Exemples d'entraînement: 35918
2025-04-19 21:47:00,758 - BERT_FakeNews - INFO - Exemples de validation: 8980
2025-04-19 21:47:00,758 - BERT_FakeNews - INFO - Chargement du tokenizer bert-base-uncased
2025-04-19 21:47:00,932 - BERT_FakeNews - INFO - Création des datasets
2025-04-19 21:47:00,932 - BERT_FakeNews - INFO - Création des dataloaders
2025-04-19 21:47:00,933 - BERT_FakeNews - INFO - Chargement du modèle bert-base-uncased
2025-04-19 21:47:01,609 - BERT_FakeNews - INFO - Initialisation de l'optimiseur
2025-04-19 21:47:01,611 - BERT_FakeNews - INFO - Mixed precision activée
2025-04-19 21:47:01,611 - BERT_FakeNews - INFO - Début de l'entraînement...
2025-04-19 21:47:01,612 - BERT_FakeNews - INFO - Début de l'epoch 1
2025-04-19 21:47:02,747 - BERT_FakeNews - INFO -   Batch 1/2245 - Loss: 0.7328 - Temps: 1.01s
2025-04-19 21:48:24,634 - BERT_FakeNews - INFO -   Batch 100/2245 - Loss: 0.0013 - Temps: 0.64s
2025-04-19 21:49:48,521 - BERT_FakeNews - INFO -   Batch 200/2245 - Loss: 0.0003 - Temps: 0.64s
2025-04-19 21:51:12,605 - BERT_FakeNews - INFO -   Batch 300/2245 - Loss: 0.0002 - Temps: 0.64s
2025-04-19 21:52:36,984 - BERT_FakeNews - INFO -   Batch 400/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 21:54:00,074 - BERT_FakeNews - INFO -   Batch 500/2245 - Loss: 0.0003 - Temps: 0.64s
2025-04-19 21:55:23,510 - BERT_FakeNews - INFO -   Batch 600/2245 - Loss: 0.0002 - Temps: 0.65s
2025-04-19 21:56:47,929 - BERT_FakeNews - INFO -   Batch 700/2245 - Loss: 0.0002 - Temps: 0.64s
2025-04-19 21:58:11,800 - BERT_FakeNews - INFO -   Batch 800/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 21:59:35,291 - BERT_FakeNews - INFO -   Batch 900/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 22:00:58,685 - BERT_FakeNews - INFO -   Batch 1000/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 22:02:23,018 - BERT_FakeNews - INFO -   Batch 1100/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:03:46,614 - BERT_FakeNews - INFO -   Batch 1200/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:05:10,231 - BERT_FakeNews - INFO -   Batch 1300/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:06:34,673 - BERT_FakeNews - INFO -   Batch 1400/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:07:58,416 - BERT_FakeNews - INFO -   Batch 1500/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:09:21,997 - BERT_FakeNews - INFO -   Batch 1600/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:10:46,073 - BERT_FakeNews - INFO -   Batch 1700/2245 - Loss: 0.0003 - Temps: 0.64s
2025-04-19 22:12:09,715 - BERT_FakeNews - INFO -   Batch 1800/2245 - Loss: 0.0004 - Temps: 0.64s
2025-04-19 22:13:32,833 - BERT_FakeNews - INFO -   Batch 1900/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 22:14:56,293 - BERT_FakeNews - INFO -   Batch 2000/2245 - Loss: 0.0002 - Temps: 0.64s
2025-04-19 22:16:19,814 - BERT_FakeNews - INFO -   Batch 2100/2245 - Loss: 0.0015 - Temps: 0.64s
2025-04-19 22:17:43,717 - BERT_FakeNews - INFO -   Batch 2200/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 22:18:21,651 - BERT_FakeNews - INFO - Fin de l'epoch 1 - Temps total: 1880.04s - Temps moyen par batch: 0.64s
2025-04-19 22:18:21,652 - BERT_FakeNews - INFO - Epoch 1/3 - Train loss: 0.0101
2025-04-19 22:18:21,654 - BERT_FakeNews - INFO - Début de l'évaluation (validation)
2025-04-19 22:26:29,273 - BERT_FakeNews - INFO - Matrice de confusion (validation):
[[4282    2]
 [   0 4696]]
2025-04-19 22:26:29,273 - BERT_FakeNews - INFO - Évaluation terminée - Temps total: 487.62s
2025-04-19 22:26:29,273 - BERT_FakeNews - INFO - Accuracy (validation): 0.9998
2025-04-19 22:26:29,274 - BERT_FakeNews - INFO - Rapport de classification (validation):
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      4284
           1       1.00      1.00      1.00      4696

    accuracy                           1.00      8980
   macro avg       1.00      1.00      1.00      8980
weighted avg       1.00      1.00      1.00      8980

2025-04-19 22:26:29,277 - BERT_FakeNews - INFO - Matrice de confusion (validation):
[[4282    2]
 [   0 4696]]
2025-04-19 22:26:29,278 - BERT_FakeNews - INFO - Matrice de confusion validation sauvegardée à ./Modele/bert_fine_tuned/confusion_matrix_validation.txt
2025-04-19 22:26:29,279 - BERT_FakeNews - INFO - Début de l'epoch 2
2025-04-19 22:26:30,126 - BERT_FakeNews - INFO -   Batch 1/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 22:27:52,509 - BERT_FakeNews - INFO -   Batch 100/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 22:29:16,254 - BERT_FakeNews - INFO -   Batch 200/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:30:39,592 - BERT_FakeNews - INFO -   Batch 300/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 22:32:03,113 - BERT_FakeNews - INFO -   Batch 400/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:33:26,813 - BERT_FakeNews - INFO -   Batch 500/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:34:50,335 - BERT_FakeNews - INFO -   Batch 600/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:36:14,427 - BERT_FakeNews - INFO -   Batch 700/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:37:38,402 - BERT_FakeNews - INFO -   Batch 800/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:39:01,399 - BERT_FakeNews - INFO -   Batch 900/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:40:24,825 - BERT_FakeNews - INFO -   Batch 1000/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:41:48,111 - BERT_FakeNews - INFO -   Batch 1100/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:43:11,728 - BERT_FakeNews - INFO -   Batch 1200/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:44:35,344 - BERT_FakeNews - INFO -   Batch 1300/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:45:58,780 - BERT_FakeNews - INFO -   Batch 1400/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 22:47:22,386 - BERT_FakeNews - INFO -   Batch 1500/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:48:45,178 - BERT_FakeNews - INFO -   Batch 1600/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:50:08,324 - BERT_FakeNews - INFO -   Batch 1700/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:51:31,611 - BERT_FakeNews - INFO -   Batch 1800/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:52:55,468 - BERT_FakeNews - INFO -   Batch 1900/2245 - Loss: 0.0002 - Temps: 0.64s
2025-04-19 22:54:19,328 - BERT_FakeNews - INFO -   Batch 2000/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 22:55:42,450 - BERT_FakeNews - INFO -   Batch 2100/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:57:05,903 - BERT_FakeNews - INFO -   Batch 2200/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 22:57:43,495 - BERT_FakeNews - INFO - Fin de l'epoch 2 - Temps total: 1874.22s - Temps moyen par batch: 0.64s
2025-04-19 22:57:43,496 - BERT_FakeNews - INFO - Epoch 2/3 - Train loss: 0.0011
2025-04-19 22:57:43,497 - BERT_FakeNews - INFO - Début de l'évaluation (validation)
2025-04-19 23:05:47,242 - BERT_FakeNews - INFO - Matrice de confusion (validation):
[[4284    0]
 [   0 4696]]
2025-04-19 23:05:47,242 - BERT_FakeNews - INFO - Évaluation terminée - Temps total: 483.74s
2025-04-19 23:05:47,242 - BERT_FakeNews - INFO - Accuracy (validation): 1.0000
2025-04-19 23:05:47,242 - BERT_FakeNews - INFO - Rapport de classification (validation):
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      4284
           1       1.00      1.00      1.00      4696

    accuracy                           1.00      8980
   macro avg       1.00      1.00      1.00      8980
weighted avg       1.00      1.00      1.00      8980

2025-04-19 23:05:47,246 - BERT_FakeNews - INFO - Matrice de confusion (validation):
[[4284    0]
 [   0 4696]]
2025-04-19 23:05:47,247 - BERT_FakeNews - INFO - Matrice de confusion validation sauvegardée à ./Modele/bert_fine_tuned/confusion_matrix_validation.txt
2025-04-19 23:05:47,248 - BERT_FakeNews - INFO - Début de l'epoch 3
2025-04-19 23:05:48,086 - BERT_FakeNews - INFO -   Batch 1/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 23:07:10,908 - BERT_FakeNews - INFO -   Batch 100/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 23:08:34,604 - BERT_FakeNews - INFO -   Batch 200/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 23:09:57,578 - BERT_FakeNews - INFO -   Batch 300/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 23:11:20,821 - BERT_FakeNews - INFO -   Batch 400/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 23:12:44,397 - BERT_FakeNews - INFO -   Batch 500/2245 - Loss: 0.0002 - Temps: 0.64s
2025-04-19 23:14:07,737 - BERT_FakeNews - INFO -   Batch 600/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 23:15:31,302 - BERT_FakeNews - INFO -   Batch 700/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 23:16:54,640 - BERT_FakeNews - INFO -   Batch 800/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 23:18:18,399 - BERT_FakeNews - INFO -   Batch 900/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 23:19:40,990 - BERT_FakeNews - INFO -   Batch 1000/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 23:21:04,009 - BERT_FakeNews - INFO -   Batch 1100/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 23:22:27,578 - BERT_FakeNews - INFO -   Batch 1200/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 23:23:52,069 - BERT_FakeNews - INFO -   Batch 1300/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 23:25:15,929 - BERT_FakeNews - INFO -   Batch 1400/2245 - Loss: 0.0004 - Temps: 0.64s
2025-04-19 23:26:39,771 - BERT_FakeNews - INFO -   Batch 1500/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 23:28:03,464 - BERT_FakeNews - INFO -   Batch 1600/2245 - Loss: 0.0003 - Temps: 0.64s
2025-04-19 23:29:27,021 - BERT_FakeNews - INFO -   Batch 1700/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 23:30:51,304 - BERT_FakeNews - INFO -   Batch 1800/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 23:32:14,518 - BERT_FakeNews - INFO -   Batch 1900/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 23:33:38,600 - BERT_FakeNews - INFO -   Batch 2000/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 23:35:02,302 - BERT_FakeNews - INFO -   Batch 2100/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 23:36:26,677 - BERT_FakeNews - INFO -   Batch 2200/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 23:37:04,082 - BERT_FakeNews - INFO - Fin de l'epoch 3 - Temps total: 1876.83s - Temps moyen par batch: 0.64s
2025-04-19 23:37:04,083 - BERT_FakeNews - INFO - Epoch 3/3 - Train loss: 0.0057
2025-04-19 23:37:04,084 - BERT_FakeNews - INFO - Début de l'évaluation (validation)
2025-04-19 23:45:10,085 - BERT_FakeNews - INFO - Matrice de confusion (validation):
[[4284    0]
 [   5 4691]]
2025-04-19 23:45:10,088 - BERT_FakeNews - INFO - Évaluation terminée - Temps total: 486.00s
2025-04-19 23:45:10,088 - BERT_FakeNews - INFO - Accuracy (validation): 0.9994
2025-04-19 23:45:10,088 - BERT_FakeNews - INFO - Rapport de classification (validation):
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      4284
           1       1.00      1.00      1.00      4696

    accuracy                           1.00      8980
   macro avg       1.00      1.00      1.00      8980
weighted avg       1.00      1.00      1.00      8980

2025-04-19 23:45:10,093 - BERT_FakeNews - INFO - Matrice de confusion (validation):
[[4284    0]
 [   5 4691]]
2025-04-19 23:45:10,093 - BERT_FakeNews - INFO - Matrice de confusion validation sauvegardée à ./Modele/bert_fine_tuned/confusion_matrix_validation.txt
2025-04-19 23:45:10,093 - BERT_FakeNews - INFO - Sauvegarde du modèle dans ./Modele/bert_fine_tuned/
2025-04-19 23:45:12,903 - BERT_FakeNews - INFO - Métriques sauvegardées dans ./Modele/bert_fine_tuned/metrics.json
2025-04-19 23:45:12,904 - BERT_FakeNews - INFO - Début des tests sur les datasets externes
2025-04-19 23:45:12,904 - BERT_FakeNews - INFO - Test sur Fake_Real dataset
2025-04-19 23:45:12,904 - BERT_FakeNews - INFO - Test sur fake_real (data/fake_real.csv)
2025-04-19 23:45:13,284 - BERT_FakeNews - INFO - Dataset chargé: 6335 exemples
2025-04-19 23:45:13,285 - BERT_FakeNews - INFO - Distribution des labels: {0: 3171, 1: 3164}
2025-04-19 23:45:13,287 - BERT_FakeNews - INFO - Début de l'évaluation (test_fake_real)
2025-04-19 23:51:38,526 - BERT_FakeNews - INFO - Matrice de confusion (test_fake_real):
[[2019 1152]
 [2633  531]]
2025-04-19 23:51:38,526 - BERT_FakeNews - INFO - Évaluation terminée - Temps total: 385.24s
2025-04-19 23:51:38,526 - BERT_FakeNews - INFO - Accuracy (test_fake_real): 0.4025
2025-04-19 23:51:38,526 - BERT_FakeNews - INFO - Rapport de classification (test_fake_real):
              precision    recall  f1-score   support

           0       0.43      0.64      0.52      3171
           1       0.32      0.17      0.22      3164

    accuracy                           0.40      6335
   macro avg       0.37      0.40      0.37      6335
weighted avg       0.37      0.40      0.37      6335

2025-04-19 23:51:38,530 - BERT_FakeNews - INFO - Matrice de confusion :
[[2019 1152]
 [2633  531]]
2025-04-19 23:51:38,531 - BERT_FakeNews - INFO - Matrice de confusion sauvegardée à ./Modele/bert_fine_tuned/confusion_matrix_fake_real.txt
2025-04-19 23:51:38,531 - BERT_FakeNews - INFO - Métriques sauvegardées dans ./Modele/bert_fine_tuned/test_metrics_fake_real.json
2025-04-19 23:51:38,534 - BERT_FakeNews - INFO - Test sur Fake_News dataset
2025-04-19 23:51:38,534 - BERT_FakeNews - INFO - Test sur fake_news (data/train.csv)
2025-04-19 23:51:39,844 - BERT_FakeNews - INFO - Dataset chargé: 20800 exemples
2025-04-19 23:51:39,846 - BERT_FakeNews - INFO - Distribution des labels: {1: 10413, 0: 10387}
2025-04-19 23:51:39,848 - BERT_FakeNews - INFO - Début de l'évaluation (test_fake_news)
2025-04-20 00:12:46,617 - BERT_FakeNews - INFO - Matrice de confusion (test_fake_news):
[[10337    50]
 [ 8002  2411]]
2025-04-20 00:12:46,617 - BERT_FakeNews - INFO - Évaluation terminée - Temps total: 1266.77s
2025-04-20 00:12:46,617 - BERT_FakeNews - INFO - Accuracy (test_fake_news): 0.6129
2025-04-20 00:12:46,617 - BERT_FakeNews - INFO - Rapport de classification (test_fake_news):
              precision    recall  f1-score   support

           0       0.56      1.00      0.72     10387
           1       0.98      0.23      0.37     10413

    accuracy                           0.61     20800
   macro avg       0.77      0.61      0.55     20800
weighted avg       0.77      0.61      0.55     20800

2025-04-20 00:12:46,627 - BERT_FakeNews - INFO - Matrice de confusion :
[[10337    50]
 [ 8002  2411]]
2025-04-20 00:12:46,628 - BERT_FakeNews - INFO - Matrice de confusion sauvegardée à ./Modele/bert_fine_tuned/confusion_matrix_fake_news.txt
2025-04-20 00:12:46,629 - BERT_FakeNews - INFO - Métriques sauvegardées dans ./Modele/bert_fine_tuned/test_metrics_fake_news.json
2025-04-20 00:12:46,646 - BERT_FakeNews - INFO - Script terminé avec succès
2025-04-20 00:12:46,646 - BERT_FakeNews - INFO - Journal complet disponible dans: logs/bert_fine_tuned_20250419_214659.log
