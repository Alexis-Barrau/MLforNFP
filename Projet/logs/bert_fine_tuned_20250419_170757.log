2025-04-19 17:07:57,749 - BERT_FakeNews - INFO - Configuration des hyperparamètres:
2025-04-19 17:07:57,749 - BERT_FakeNews - INFO - {
  "MAX_LEN": 512,
  "BATCH_SIZE": 16,
  "EPOCHS": 3,
  "LEARNING_RATE": 3e-05,
  "RANDOM_SEED": 42,
  "MODEL_NAME": "bert-base-uncased",
  "OUTPUT_DIR": "./Modele/bert_fine_tuned/",
  "USE_MIXED_PRECISION": true
}
2025-04-19 17:07:57,852 - BERT_FakeNews - INFO - Utilisation de l'appareil: cuda
2025-04-19 17:07:57,852 - BERT_FakeNews - INFO - Chargement des données depuis data/Fake.csv et data/True.csv
2025-04-19 17:07:58,653 - BERT_FakeNews - INFO - Données fake news chargées: 23481 exemples
2025-04-19 17:07:59,379 - BERT_FakeNews - INFO - Données true news chargées: 21417 exemples
2025-04-19 17:07:59,386 - BERT_FakeNews - INFO - Total d'exemples: 44898
2025-04-19 17:07:59,388 - BERT_FakeNews - INFO - Distribution des labels: {1: 23481, 0: 21417}
2025-04-19 17:07:59,405 - BERT_FakeNews - INFO - Exemples d'entraînement: 35918
2025-04-19 17:07:59,405 - BERT_FakeNews - INFO - Exemples de validation: 8980
2025-04-19 17:07:59,405 - BERT_FakeNews - INFO - Chargement du tokenizer bert-base-uncased
2025-04-19 17:08:01,349 - BERT_FakeNews - INFO - Création des datasets
2025-04-19 17:08:01,349 - BERT_FakeNews - INFO - Création des dataloaders
2025-04-19 17:08:01,350 - BERT_FakeNews - INFO - Chargement du modèle bert-base-uncased
2025-04-19 17:08:08,475 - BERT_FakeNews - INFO - Initialisation de l'optimiseur
2025-04-19 17:08:08,477 - BERT_FakeNews - INFO - Mixed precision activée
2025-04-19 17:08:08,477 - BERT_FakeNews - INFO - Début de l'entraînement...
2025-04-19 17:08:08,478 - BERT_FakeNews - INFO - Début de l'epoch 1
2025-04-19 17:08:09,768 - BERT_FakeNews - INFO -   Batch 1/2245 - Loss: 0.7109 - Temps: 1.14s
2025-04-19 17:09:32,020 - BERT_FakeNews - INFO -   Batch 100/2245 - Loss: 0.0048 - Temps: 0.64s
2025-04-19 17:10:55,039 - BERT_FakeNews - INFO -   Batch 200/2245 - Loss: 0.0003 - Temps: 0.64s
2025-04-19 17:12:18,136 - BERT_FakeNews - INFO -   Batch 300/2245 - Loss: 0.0009 - Temps: 0.64s
2025-04-19 17:13:41,618 - BERT_FakeNews - INFO -   Batch 400/2245 - Loss: 0.0002 - Temps: 0.64s
2025-04-19 17:15:05,230 - BERT_FakeNews - INFO -   Batch 500/2245 - Loss: 0.0002 - Temps: 0.64s
2025-04-19 17:16:28,309 - BERT_FakeNews - INFO -   Batch 600/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 17:17:51,392 - BERT_FakeNews - INFO -   Batch 700/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 17:19:15,245 - BERT_FakeNews - INFO -   Batch 800/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 17:20:38,250 - BERT_FakeNews - INFO -   Batch 900/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 17:22:02,172 - BERT_FakeNews - INFO -   Batch 1000/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 17:23:25,484 - BERT_FakeNews - INFO -   Batch 1100/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 17:24:48,197 - BERT_FakeNews - INFO -   Batch 1200/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 17:26:12,528 - BERT_FakeNews - INFO -   Batch 1300/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 17:27:37,060 - BERT_FakeNews - INFO -   Batch 1400/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 17:29:02,871 - BERT_FakeNews - INFO -   Batch 1500/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 17:30:26,136 - BERT_FakeNews - INFO -   Batch 1600/2245 - Loss: 0.0001 - Temps: 0.64s
2025-04-19 17:31:49,264 - BERT_FakeNews - INFO -   Batch 1700/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 17:33:13,531 - BERT_FakeNews - INFO -   Batch 1800/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 17:34:37,297 - BERT_FakeNews - INFO -   Batch 1900/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 17:36:00,870 - BERT_FakeNews - INFO -   Batch 2000/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 17:37:24,748 - BERT_FakeNews - INFO -   Batch 2100/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 17:38:48,513 - BERT_FakeNews - INFO -   Batch 2200/2245 - Loss: 0.0000 - Temps: 0.64s
2025-04-19 17:39:26,483 - BERT_FakeNews - INFO - Fin de l'epoch 1 - Temps total: 1878.00s - Temps moyen par batch: 0.64s
2025-04-19 17:39:26,485 - BERT_FakeNews - INFO - Epoch 1/3 - Train loss: 0.0105
2025-04-19 17:39:26,486 - BERT_FakeNews - INFO - Début de l'évaluation (validation)
2025-04-19 17:47:32,905 - BERT_FakeNews - INFO - Matrice de confusion (validation):
[[4284    0]
 [   0 4696]]
2025-04-19 17:47:32,905 - BERT_FakeNews - INFO - Évaluation terminée - Temps total: 486.42s
2025-04-19 17:47:32,905 - BERT_FakeNews - INFO - Accuracy (validation): 1.0000
2025-04-19 17:47:32,905 - BERT_FakeNews - INFO - Rapport de classification (validation):
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      4284
           1       1.00      1.00      1.00      4696

    accuracy                           1.00      8980
   macro avg       1.00      1.00      1.00      8980
weighted avg       1.00      1.00      1.00      8980

2025-04-19 17:47:32,910 - BERT_FakeNews - INFO - Matrice de confusion (validation):
[[4284    0]
 [   0 4696]]
