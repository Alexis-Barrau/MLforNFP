{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9022caf-63b0-4c23-b976-1c35decadf02",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57284443-3374-4905-a6ed-2dd911edc597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les embeddings des datasets\n",
    "embeddings_fake_news_df = pd.read_csv(\"data/Embedded/embeddings_fake_news_base_bert.csv\")\n",
    "embeddings_isot_df = pd.read_csv(\"data/Embedded/embeddings_isot_base_bert.csv\")\n",
    "embeddings_fake_real_df = pd.read_csv(\"data/Embedded/embeddings_fake_real_base_bert.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5629be-2f6f-4685-97f1-cf26f58a8cda",
   "metadata": {},
   "source": [
    "# True de Fake-News et Fake de ISOT\n",
    "\n",
    "On se propose de tester ce que cela donne lorsque l'on entraine sur un mix des datasets, comme nous l'avons fait pour le TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97aa2459-8e77-4442-925d-92dbb3ffd715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    11784\n",
      "0    10387\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Création de notre dataset\n",
    "embeddings_isot_df_sub = embeddings_isot_df.sample(frac=0.5, random_state=42)\n",
    "true_from_fake_news = embeddings_fake_news_df[embeddings_fake_news_df['label'] == 0]\n",
    "fake_from_isot = embeddings_isot_df_sub[embeddings_isot_df_sub['label'] == 1]\n",
    "\n",
    "combined_df = pd.concat([true_from_fake_news, fake_from_isot], ignore_index=True)\n",
    "print(combined_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b7976c-8de5-46a7-9b33-24741cd70f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps pour fit : 4.09 secondes\n",
      "Accuracy: 0.9950394588500564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      2097\n",
      "           1       0.99      1.00      1.00      2338\n",
      "\n",
      "    accuracy                           1.00      4435\n",
      "   macro avg       1.00      0.99      1.00      4435\n",
      "weighted avg       1.00      1.00      1.00      4435\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2083   14]\n",
      " [   8 2330]]\n"
     ]
    }
   ],
   "source": [
    "# Réalisation du modèle\n",
    "X = combined_df.drop(columns=['label']).values\n",
    "y = combined_df['label'].values\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement\n",
    "classifier_combined = LogisticRegression(max_iter=1000)\n",
    "start_time = time.time()\n",
    "classifier_combined.fit(X_train, y_train)\n",
    "print(f\"Temps pour fit : {time.time() - start_time:.2f} secondes\")\n",
    "\n",
    "# Évaluation\n",
    "y_pred = classifier_combined.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8baa693-642e-4975-92ad-e3fabe9e6be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Modele/base_bert_logistic_combined.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On enregistre le modèle\n",
    "joblib.dump(classifier_combined, \"Modele/base_bert_logistic_combined.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "772d2b52-fe9e-4228-a76d-50b7a723cf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5318074191002368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.66      0.58      3171\n",
      "           1       0.54      0.40      0.46      3164\n",
      "\n",
      "    accuracy                           0.53      6335\n",
      "   macro avg       0.53      0.53      0.52      6335\n",
      "weighted avg       0.53      0.53      0.52      6335\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2088 1083]\n",
      " [1883 1281]]\n"
     ]
    }
   ],
   "source": [
    "# Test sur fake_real\n",
    "\n",
    "X_fake_real = embeddings_fake_real_df.drop(columns=['label']).values\n",
    "y_fake_real = embeddings_fake_real_df['label'].values\n",
    "\n",
    "# Prédictions\n",
    "y_fake_real_pred = classifier_combined.predict(X_fake_real)\n",
    "\n",
    "# Évaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_fake_real, y_fake_real_pred))\n",
    "print(classification_report(y_fake_real, y_fake_real_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_fake_real, y_fake_real_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cbc35d-3a54-4bac-85c5-20435783c6c4",
   "metadata": {},
   "source": [
    "Et ceci est étonamment mauvais...\n",
    "\n",
    "# Mélange des deux datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af73d3fb-6b21-4841-b582-d2d8f3a87ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Data 1:\n",
      "label\n",
      "1    11079\n",
      "0    10526\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Mixed Data 2:\n",
      "label\n",
      "1    11079\n",
      "0    10526\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Création de dataset mélangé\n",
    "\n",
    "# Séparer les vraies et fausses news\n",
    "isot_real = embeddings_isot_df_sub[embeddings_isot_df_sub['label'] == 1]\n",
    "isot_fake = embeddings_isot_df_sub[embeddings_isot_df_sub['label'] == 0]\n",
    "\n",
    "fake_news_real = embeddings_fake_news_df[embeddings_fake_news_df['label'] == 1]\n",
    "fake_news_fake = embeddings_fake_news_df[embeddings_fake_news_df['label'] == 0]\n",
    "\n",
    "# On sépare aléatoirement nos datasets\n",
    "isot_real_1 = isot_real.sample(frac=0.5, random_state=42)\n",
    "isot_real_2 = isot_real.drop(isot_real_1.index)\n",
    "\n",
    "isot_fake_1 = isot_fake.sample(frac=0.5, random_state=42)\n",
    "isot_fake_2 = isot_fake.drop(isot_fake_1.index)\n",
    "\n",
    "fake_news_real_1 = fake_news_real.sample(frac=0.5, random_state=42)\n",
    "fake_news_real_2 = fake_news_real.drop(fake_news_real_1.index)\n",
    "\n",
    "fake_news_fake_1 = fake_news_fake.sample(frac=0.5, random_state=42)\n",
    "fake_news_fake_2 = fake_news_fake.drop(fake_news_fake_1.index)\n",
    "\n",
    "# Créer mixed_data_1 avec 50 % des vraies et fausses informations de chaque dataset\n",
    "mixed_data_1 = pd.concat([isot_real_1, isot_fake_1, fake_news_real_1, fake_news_fake_1], ignore_index=True)\n",
    "\n",
    "# Créer mixed_data_2 avec le reste des observations non présentes dans mixed_data_1\n",
    "mixed_data_2 = pd.concat([isot_real_2, isot_fake_2, fake_news_real_2, fake_news_fake_2], ignore_index=True)\n",
    "\n",
    "# Mélanger les datasets pour éviter toute structure dans les données\n",
    "mixed_data_1 = mixed_data_1.sample(frac=1, random_state=5).reset_index(drop=True)\n",
    "mixed_data_2 = mixed_data_2.sample(frac=1, random_state=6).reset_index(drop=True)\n",
    "\n",
    "# Vérification\n",
    "print(\"Mixed Data 1:\")\n",
    "print(mixed_data_1['label'].value_counts())\n",
    "\n",
    "print(\"\\nMixed Data 2:\")\n",
    "print(mixed_data_2['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7188703d-43cf-44e1-a53b-eeb4f1c1b117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9453830131913908\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      2075\n",
      "           1       0.96      0.94      0.95      2246\n",
      "\n",
      "    accuracy                           0.95      4321\n",
      "   macro avg       0.95      0.95      0.95      4321\n",
      "weighted avg       0.95      0.95      0.95      4321\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1976   99]\n",
      " [ 137 2109]]\n"
     ]
    }
   ],
   "source": [
    "# Notre modèle sur mixed_data_1\n",
    "\n",
    "# On réalise le split des données\n",
    "\n",
    "X = mixed_data_1.drop(columns=['label']).values\n",
    "y = mixed_data_1['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#On applique une régression logistique\n",
    "classifier_mixed_1 = LogisticRegression(max_iter=1000)\n",
    "classifier_mixed_1.fit(X_train, y_train)\n",
    "\n",
    "# Et on évalue notre petit modèle\n",
    "y_pred = classifier_mixed_1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac67dc4e-d43f-4bfd-a0b8-b3a411dd0ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7226519337016575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.55      0.66      3171\n",
      "           1       0.66      0.90      0.76      3164\n",
      "\n",
      "    accuracy                           0.72      6335\n",
      "   macro avg       0.75      0.72      0.71      6335\n",
      "weighted avg       0.75      0.72      0.71      6335\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1741 1430]\n",
      " [ 327 2837]]\n"
     ]
    }
   ],
   "source": [
    "# Test sur Fake_real\n",
    "# Prédictions\n",
    "y_fake_real_pred = classifier_mixed_1.predict(X_fake_real)\n",
    "\n",
    "# Évaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_fake_real, y_fake_real_pred))\n",
    "print(classification_report(y_fake_real, y_fake_real_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_fake_real, y_fake_real_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a24a6c3e-f1b7-4e8f-83c2-e07b4c5694f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9435315899097431\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.94      2088\n",
      "           1       0.95      0.94      0.95      2233\n",
      "\n",
      "    accuracy                           0.94      4321\n",
      "   macro avg       0.94      0.94      0.94      4321\n",
      "weighted avg       0.94      0.94      0.94      4321\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1979  109]\n",
      " [ 135 2098]]\n"
     ]
    }
   ],
   "source": [
    "# Notre modèle sur mixed_data_2\n",
    "\n",
    "# On réalise le split des données\n",
    "\n",
    "X = mixed_data_2.drop(columns=['label']).values\n",
    "y = mixed_data_2['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#On applique une régression logistique\n",
    "classifier_mixed_2 = LogisticRegression(max_iter=1000)\n",
    "classifier_mixed_2.fit(X_train, y_train)\n",
    "\n",
    "# Et on évalue notre petit modèle\n",
    "y_pred = classifier_mixed_2.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5d33424-c740-4fdc-92e6-a7d5767d587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7291239147592739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.57      0.68      3171\n",
      "           1       0.67      0.89      0.77      3164\n",
      "\n",
      "    accuracy                           0.73      6335\n",
      "   macro avg       0.76      0.73      0.72      6335\n",
      "weighted avg       0.76      0.73      0.72      6335\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1800 1371]\n",
      " [ 345 2819]]\n"
     ]
    }
   ],
   "source": [
    "# Test sur Fake_real\n",
    "# Prédictions\n",
    "y_fake_real_pred = classifier_mixed_2.predict(X_fake_real)\n",
    "\n",
    "# Évaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_fake_real, y_fake_real_pred))\n",
    "print(classification_report(y_fake_real, y_fake_real_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_fake_real, y_fake_real_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d45555-42b4-4674-853d-243ba6e04d52",
   "metadata": {},
   "source": [
    "Conclusion de cette exploration : \n",
    "- le mélange entre ISOT et fake_news n'apporte de réel gains que si l'on prends des vraies nouvelles et des fake news\n",
    "- Evalué sur fake_real, on a gain limité, de 7 points."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
